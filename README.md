# Andrew-Ng-Machine-Learning-Excercise
# 吴恩达机器学习练习

This is a practicing coding for Andrew Ng's course of Machine Learning, which will be submitted to the Coursera. 

这是我对于吴恩达的机器学习课程的学习中所做的练习代码，将会被提交给Coursera进行评分。


## Courses Learning
## 课程学习

Learning this course using the "[Andrew Ng's Machine Learning](https://study.163.com/course/courseLearn.htm?courseId=1004570029)" published by "Netease Cloud Classroom"

课程学习使用“网易云课堂”中的《[吴恩达机器学习](https://study.163.com/course/courseLearn.htm?courseId=1004570029)》视频系列。

Submitting the answer from the Coursera's system, since I attened to the same online class starts from 26 Feb., 2019.

提交作业使用Coursera的作业系统，我参加了2019年2月26日(?)开始的Coursera课程。

## Notes
## 备注

1.Exercise-1 has been accpeted by the system on 23 March 2015, since I have been enrolled into this class (marked 100/100). For the time gap is too long, I would check this code later. 

因为以前曾参加过此课程，练习-1已在2015年3月23日被成功提交，分数为100/100。时间间隔太长，我将会后续补上此代码。

2.This is a record for my own coding process, and I would like you to download, explore or play with these codes。 But I am **STRONGLY NOT RECOMMEND** you to submit this code to the Coursera directly, because it is a **VIOLATION** to the **HONOR CODE**.

此项目记录了我自己的代码编写过程，我十分欢迎您下载、研究、探索这份作业的代码。但是我**强烈不推荐**您将这份代码毫无改动的当作您自己的作业上传至Coursera，因为这样已经**违反**了**诚信协议**。

## Scores
## 成绩记录

**machine-learning-ex1**

Submitted on 23 March 2015 at 3:59 PM</br>
提交时间 23 March 2015 在 3:59 PM

Score(成绩) 100% </br>

|Part</br>部分|Name</br>名称|Socre</br>分数|
| :-:   | :-----:  | :----: |
|1|	Warm up exercise	|10 / 10
|2|	Compute cost for one variable	|40 / 40
|3|	Gradient descent for one variable	|50 / 50
|4|	Feature normalization	|0 / 0
|5|	Compute cost for multiple variables	|0 / 0
|6|	Gradient descent for multiple variables	|0 / 0
|7|	Normal equations	|0 / 0

**machine-learning-ex2**

Submitted on 9 March 2019 at 1:20 AM</br>
提交时间 9 March 2019 在 1:20 AM

Score(成绩) 100% </br>

|Part</br>部分|Name</br>名称|Socre</br>分数|
| :-:   | :-----:  | :----: |
1|	Sigmoid function|	5 / 5
2|	Compute cost for logistic regression|	30 / 30
3|	Gradient for logistic regression|	30 / 30
4|	Predict function	|5 / 5
5|	Compute cost for regularized LR	|15 / 15
6|	Gradient for regularized LR	|15 / 15




